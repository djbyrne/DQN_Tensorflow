# DQN_Tensorflow
This repo consists of a Jupyter Notebook that implements the DQN model. The goal of this notebook was to build a clean, modular and easy to understand implementation of DQN. This is certainly not the most efficient implementation but I hope that it is at least very clear. The agent is trained in the VizDoom environment using the basic scenario. I chose this scenario because I believe it is an excellent test case for quickly prototyping agents in a computer vision based environment. The scenario can be beaten with just a few minutes of training. This allows us to quickly varify if our agent is working correctly. I hope that this implementation is able to help someone else better understand this topic.

# To Do:
 - Saver function
 - Training plots
 - Test/viewing epochs
 - Fixed target network
 - Dueling Network
 - Double DQN
 - Prioritized Experience Replay
 - N-step

# References
 - VizDoom Tensorflow Example: https://github.com/mwydmuch/ViZDoom/blob/master/examples/python/learning_tensorflow.py
 - Lets Make A DQN: https://jaromiru.com/2016/10/03/lets-make-a-dqn-implementation/
 - Introduction To Deep Q Learning:
https://medium.freecodecamp.org/an-introduction-to-deep-q-learning-lets-play-doom-54d02d8017d8
